<script type="text/javascript" async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

## 算法收敛性

定理(Novikoff):设训练数据集$$T=\{(x_{1},y_{1}),(x_{2},y_{2}),....,(x_{n},y_{n})\}$$是线性可分的，其中$$x_{i} \in X=R^{n},y_{i} \in Y=\{-1,1\},i=1,2,...N$$,则

（1）存在满足条件的$$\parallel \hat{w}_{opt} \parallel =1$$的超平面$$\hat{w}_{opt} \cdot \hat{x} =w_{opt} \cdot x + b_{opt}=0$$将训练数据集完全正确分开；且存在$$\gamma >0$$,对所有i=1,2,...N。
$$y_{i}(\hat{w}_{opt}\cdot\hat{x_{i}})=y_{i}(w_{opt}\cdot x_{i}+b_{opt}) \ge \gamma$$

（2）令$$R=max_{1 \le i \le N}\parallel\hat{x}_{i}\parallel$$,则感知机算法2.1在训练数据集上的误分类次数k满足不等式

$$k \le (\frac{R}{\gamma})^{2}$$

证明：

（1）由于训练数据集是线性可分的，按照定义2.2，存在超平面可将训练数据集完全正确分开，取超平面为$$\hat{w_{opt}}\cdot\hat{x}=w_{opt}\cdot x+b_{opt}=0,使 \parallel\hat{w}_{opt}\parallel=1$$.由于对有限的$$i=1,2,....,N$$均有$$y_{i}(\hat{w}_{opt}\cdot\hat{x}_{i})=y_{i}(w_{opt}\cdot x_{i}+b_{opt})>0$$,所以存在$$\gamma=min_{i}\{y_{i}(w_{opt}\cdot x_{i}+b_{opt})\}$$使得$$y_{i}(\hat{w}_{opt}\cdot\hat{x}_{i})=y_{i}(w_{opt}\cdot x_{i}+b_{opt}) \ge \gamma$$

（2）感知机从$$\hat{w}_{0}=0$$开始，如果实例被误分类，则更新权重。令$$\hat{w}_{k-1}$$是第k个误分类实例之前的扩充权重向量$$\hat{w}_{k-1}=(w^{T}_{k-1},b_{k-1})^{T}$$